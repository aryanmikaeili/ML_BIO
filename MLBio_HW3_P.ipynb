{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "efrE1Lc0Otrq"
   },
   "source": [
    "# **Machine Learning in Bioinformatics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GtzvENmYOtxi"
   },
   "source": [
    "**Homework 3:**<br/>\n",
    "!!! If you don't fill these fields, your homework does not count !!!<br/>\n",
    "first name and last name : Aryan Mikaeili<br/>\n",
    "student number : 95105895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KG3vb72VOt4G"
   },
   "source": [
    "You can run cells by hitting `Shift` + `Enter` or `ctrl` + `Enter`.<br/>\n",
    "We highly recommend you to read each line of code carefully and try to \n",
    "understand what it exactly does.<br/>\n",
    "Just alter the parts that is between green comments and specified for you. <br/>\n",
    "Please do not change other parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v0dotHjRO5x_"
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer \n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_5C6lgUtO-bg"
   },
   "source": [
    "\n",
    "### about the Data:<br/>\n",
    "The purpose of this project is to classify tumors into malignant or benign. The following dataset is constructed based on images of tumors. Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.\n",
    "For more details about the features of this dataset you can visit this link:\n",
    "https://scikit-learn.org/stable/datasets/index.html#breast-cancer-dataset<br/>\n",
    "This dataset contains 30 features and 1 label called target.\n",
    "The original dataset labels are 0 and 1 and in the following code boxes we change it to -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-7_g8ApcO7tm"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890     0.0  \n",
       "1          0.2750                  0.08902     0.0  \n",
       "2          0.3613                  0.08758     0.0  \n",
       "3          0.6638                  0.17300     0.0  \n",
       "4          0.2364                  0.07678     0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = load_breast_cancer()  ## change if the data set changed\n",
    "df = pd.DataFrame(np.c_[cancer[\"data\"], cancer[\"target\"]], columns = np.append(cancer[\"feature_names\"],[\"target\"]))\n",
    "features = ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jmmK95OVPDyg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.94727592267135 %\n",
      "69.94727592267135 %\n",
      "20.035149384885763 %\n",
      "20.035149384885763 %\n",
      "10.017574692442881 %\n",
      "10.017574692442881 %\n"
     ]
    }
   ],
   "source": [
    "cancer.target = np.where(cancer.target==0, -1, cancer.target)\n",
    "X_train ,X_test ,X_val ,y_train ,y_test ,y_val = None ,None ,None ,None ,None ,None\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# 1- Normalize tha data.                                                       #\n",
    "# 2- using train_test_split package, split your data into 3 numpy array        #\n",
    "# called X_train, X_test, and X_val and also split the corresponding labels as #\n",
    "# y_train, y_test, and y_val. After spliting, the ratio of your data should be # \n",
    "# approximately like this:                                                     #\n",
    "#  Train : 70%     test : 20%       validation : 10%                           #\n",
    "################################################################################\n",
    "X = cancer[\"data\"]\n",
    "Y = cancer[\"target\"]\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#scaler = MinMaxScaler()\n",
    "#X_p = scaler.fit_transform(X)\n",
    "X = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis = 0))\n",
    "test_ratio = 0.2\n",
    "validation_ratio = 0.1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, shuffle=True, test_size= test_ratio)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size= validation_ratio /(1 - test_ratio))\n",
    "\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "print((X_train.shape[0]/cancer.data.shape[0]) * 100, \"%\")\n",
    "print((y_train.shape[0]/cancer.data.shape[0]) * 100, \"%\")\n",
    "print((X_test.shape[0]/cancer.data.shape[0]) * 100, \"%\")\n",
    "print((y_test.shape[0]/cancer.data.shape[0]) * 100, \"%\")\n",
    "print((X_val.shape[0]/cancer.data.shape[0]) * 100, \"%\")\n",
    "print((y_val.shape[0]/cancer.data.shape[0]) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EZ3-Fm4uPIdf"
   },
   "source": [
    "# Ensemble Methods\n",
    "\n",
    "## Problem 1. Bagging (15 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZzSuFIANPPRh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9649122807017544\n",
      "2 0.9649122807017544\n",
      "3 0.9649122807017544\n",
      "4 0.9649122807017544\n",
      "5 0.9824561403508771\n",
      "6 0.9824561403508771\n",
      "7 0.9824561403508771\n",
      "8 0.9824561403508771\n",
      "9 0.9824561403508771\n",
      "10 1.0\n",
      "11 0.9824561403508771\n",
      "12 0.9824561403508771\n",
      "13 0.9824561403508771\n",
      "14 1.0\n",
      "15 0.9824561403508771\n",
      "16 0.9824561403508771\n",
      "17 0.9824561403508771\n",
      "18 0.9824561403508771\n",
      "19 0.9824561403508771\n",
      "20 0.9824561403508771\n",
      "21 0.9824561403508771\n",
      "22 0.9824561403508771\n",
      "23 0.9824561403508771\n",
      "24 0.9824561403508771\n",
      "25 0.9824561403508771\n",
      "26 0.9824561403508771\n",
      "27 0.9824561403508771\n",
      "28 0.9824561403508771\n",
      "29 0.9824561403508771\n",
      "30 0.9824561403508771\n",
      "31 0.9824561403508771\n",
      "32 0.9824561403508771\n",
      "33 0.9824561403508771\n",
      "34 0.9824561403508771\n",
      "35 0.9824561403508771\n",
      "36 0.9824561403508771\n",
      "37 0.9824561403508771\n",
      "38 0.9824561403508771\n",
      "39 0.9824561403508771\n",
      "40 0.9824561403508771\n",
      "41 0.9824561403508771\n",
      "42 0.9824561403508771\n",
      "43 0.9824561403508771\n",
      "44 0.9824561403508771\n",
      "45 0.9824561403508771\n",
      "46 0.9824561403508771\n",
      "47 0.9824561403508771\n",
      "48 0.9824561403508771\n",
      "49 0.9824561403508771\n",
      "50 0.9824561403508771\n",
      "51 0.9824561403508771\n",
      "52 0.9824561403508771\n",
      "53 0.9824561403508771\n",
      "54 0.9824561403508771\n",
      "55 0.9824561403508771\n",
      "56 0.9824561403508771\n",
      "57 0.9824561403508771\n",
      "58 0.9824561403508771\n",
      "59 0.9824561403508771\n",
      "60 0.9824561403508771\n",
      "61 0.9824561403508771\n",
      "62 0.9824561403508771\n",
      "63 0.9824561403508771\n",
      "64 0.9824561403508771\n",
      "65 0.9824561403508771\n",
      "66 0.9824561403508771\n",
      "67 0.9824561403508771\n",
      "68 0.9824561403508771\n",
      "69 0.9824561403508771\n",
      "70 0.9824561403508771\n",
      "71 0.9824561403508771\n",
      "72 0.9824561403508771\n",
      "73 0.9824561403508771\n",
      "74 0.9824561403508771\n",
      "75 0.9824561403508771\n",
      "76 0.9824561403508771\n",
      "77 0.9824561403508771\n",
      "78 0.9824561403508771\n",
      "79 0.9824561403508771\n",
      "80 0.9824561403508771\n",
      "81 0.9824561403508771\n",
      "82 0.9824561403508771\n",
      "83 0.9824561403508771\n",
      "84 0.9824561403508771\n",
      "85 0.9824561403508771\n",
      "86 0.9824561403508771\n",
      "87 0.9824561403508771\n",
      "88 0.9824561403508771\n",
      "89 0.9824561403508771\n",
      "90 0.9824561403508771\n",
      "91 0.9824561403508771\n",
      "92 0.9824561403508771\n",
      "93 0.9824561403508771\n",
      "94 0.9824561403508771\n",
      "95 0.9824561403508771\n",
      "96 0.9824561403508771\n",
      "97 0.9824561403508771\n",
      "98 0.9824561403508771\n",
      "99 0.9824561403508771\n",
      "100 0.9824561403508771\n",
      "97.36842105263158\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2f6289e3208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import model_selection \n",
    "from sklearn.ensemble import BaggingClassifier \n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# TODO : initialize the base classifier. You can choose one of the classifiers #\n",
    "# you have learned in this course.(SVM/Decision tree)                          #\n",
    "# IMPORTANT: if you are using SVM as base classifier don't forget to add column#\n",
    "# of '1' s for bias and be careful to use the right datset in next parts.      #\n",
    "################################################################################\n",
    "base_cls = None\n",
    "\n",
    "X_train_biased = np.insert(X_train, 0, 1, axis=1)\n",
    "X_val_biased = np.insert(X_val, 0, 1, axis=1)\n",
    "X_test_biased = np.insert(X_test, 0, 1, axis = 1)\n",
    "base_cls = sklearn.linear_model.Perceptron(tol=1e-3, random_state=0)\n",
    "\n",
    "##################################################################################\n",
    "# TODO: Number of classifiers is a hyperparameter. Choose it by using validation #\n",
    "# data to have the best accuracy                                                 #\n",
    "# For different number of classifiers, train the model with training data and    #\n",
    "# compute accuracy for validation data. Plot accuracy-number of classifiers plot.#\n",
    "##################################################################################\n",
    "def accuracy(preds, labels):\n",
    "    return len(np.argwhere(preds == labels)) / len(labels)\n",
    "\n",
    "num_cls = 10\n",
    "seed = 22\n",
    " \n",
    "max_num_cls = 100\n",
    "accuracies = []\n",
    "models = []\n",
    "for num_cls in range(1,max_num_cls + 1):\n",
    "    base_cls = sklearn.linear_model.Perceptron(tol=1e-3, random_state=seed)\n",
    "    model = BaggingClassifier(base_estimator = base_cls,\n",
    "                              n_estimators = num_cls,\n",
    "                              random_state = seed)\n",
    "    model.fit(X_train_biased,y_train)\n",
    "    models.append(model)\n",
    "    preds = model.predict(X_val_biased)\n",
    "    print(num_cls, accuracy(preds, y_val))\n",
    "    accuracies.append(accuracy(preds, y_val))\n",
    "\n",
    "\n",
    "plt.plot([(i + 1) for i in range(0, max_num_cls)], accuracies)\n",
    "################################################################################\n",
    "# compute and report the accuracy for test data.                               #\n",
    "################################################################################\n",
    "best_num = np.argmax(accuracies)\n",
    "model = models[best_num]\n",
    "preds = model.predict(X_test_biased)\n",
    "\n",
    "print(accuracy(preds, y_test) * 100)\n",
    "#print(accuracy_score(y_test, preds) * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ELyA0acXgK2w"
   },
   "source": [
    "## Problem 2. Random Forest(25 points)</br>\n",
    "In this part, you should write your own code to classify the data, using random forest from sklearn package in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JE4eKUybgQUb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  93.85964912280701\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.89      0.92        46\n",
      "           1       0.93      0.97      0.95        68\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "[[41  5]\n",
      " [ 2 66]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "#################################################################################\n",
    "# TODO:use the validation data to determine hyperparameters(number and depth of #\n",
    "# trees) for the best accuracy                                                  # \n",
    "#################################################################################\n",
    "min_depth = 5\n",
    "max_depth = 20\n",
    "min_num = 50\n",
    "max_num = 150\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier( criterion=\"entropy\", bootstrap=True, random_state=10, oob_score=True, max_features=\"auto\")\n",
    "\n",
    "best_accuracy = 0\n",
    "best_depth = 5\n",
    "best_num = 100\n",
    "\n",
    "\n",
    "use_oob = True\n",
    "\n",
    "if use_oob:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, shuffle=True, test_size= test_ratio)\n",
    "\n",
    "for n in range(min_num, max_num, 10):\n",
    "    for d in range(min_depth, max_depth):\n",
    "        rf.set_params(n_estimators = n, max_depth = d)\n",
    "        rf.fit(X_train, y_train)\n",
    "        if use_oob:\n",
    "            score = rf.oob_score_\n",
    "        else:\n",
    "            preds = rf.predict(X_val)\n",
    "            score = accuracy_score(y_val, preds)\n",
    "\n",
    "        if score > best_accuracy:\n",
    "            best_accuracy = score\n",
    "            best_depth = d\n",
    "            best_num = n\n",
    "       \n",
    "\n",
    "rf.set_params(n_estimators = best_num, max_depth = best_depth)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "preds = rf.predict(X_test)\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "#TODO:report accuracy, presition,recall and confusion matrix for train and test data  #\n",
    "#######################################################################################\n",
    "\n",
    "print(\"accuracy : \", accuracy_score(y_test, preds) * 100)\n",
    "print(classification_report(y_test, preds))\n",
    "print(confusion_matrix(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pSr7G0fdgmyf"
   },
   "source": [
    "Question:\n",
    "Explain how you did choose the hyperparameters.</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "etxNZ36Ugnp7"
   },
   "source": [
    "The hyperparamater choosing method can be chosen by setting the use_oob variable to True or False. If set true, the code will use out of bag samples for validation, and if not, it will simply use the validation data. Ofcourse in the latter, we can merge the training and validation data, so the model can learn from a larger data, and get a better accuarcy. Also another advantage of this method is that for each tree at least 30% of the training data is out-of-bag data, so the model can validate on a data nearly 3 times larger than the 10% validation data we originally had.\n",
    "In the out-of-bag validation method, the model will use each data value, on the trees that were not trained on that data(were not present in it's bootstrap), and predicts the value of it's label. finally the moddel will calculate the accuracy of the model on all the datapoints, using this method. We can then use this accuracy to find the best hyperparamaters for our model.\n",
    "For the model, I used the values between 5 to 20 for the maximum depth of each tree and valuse between 50 to 150 for the number of trees. Then I did a grid search on these values(checked every combination of the two) and chose the best hyperparameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fxpbM42MPg6m"
   },
   "source": [
    "## Problem 3. Boosting : AdaBoost (35 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rUodQdBvPrKQ"
   },
   "source": [
    "In this part you should implement adaptive boosting algorithm. </br>\n",
    "<picture>\n",
    "  <img src=\"http://uupload.ir/files/b919_adaboost.png\" alt=\"Adaboost\" width=\"600\" height=\"300\">\n",
    "</picture>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r9TL5FGqRIoL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data accuracy is: 92.52692459398742 %\n",
      "The test data accuracy is: 88.78667908709828 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "X_train ,X_test ,y_train ,y_test = None ,None ,None ,None\n",
    "###################################################################\n",
    "# TODO: use 80% of normalized data as train and 20% as test data. #\n",
    "###################################################################\n",
    "cancer = load_breast_cancer()  ## change if the data set changed\n",
    "df = pd.DataFrame(np.c_[cancer[\"target\"], cancer[\"data\"]], columns = np.append([\"target\"], cancer[\"feature_names\"]))\n",
    "features = ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n",
    "cancer.target = np.where(cancer.target==0, -1, cancer.target)\n",
    "\n",
    "X = cancer[\"data\"]\n",
    "Y = cancer[\"target\"]\n",
    "X = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis = 0))\n",
    "\n",
    "test_ratio = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, shuffle=True, test_size= test_ratio)\n",
    "\n",
    "######################################################################\n",
    "#TODO : define a weak decision tree.                                 #\n",
    "# initialize these parameters: criterion=\"entropy\" and max_depth = 1 #\n",
    "######################################################################\n",
    "Tree_model = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 1)\n",
    "#############################################################################################\n",
    "#TODO : report accuracy of your weak model on train and test data by using cross validation #\n",
    "#############################################################################################\n",
    "\n",
    "accuracy =cross_validate(Tree_model,X_train, y_train, cv=4, return_train_score=True)\n",
    "train_accuracy = np.mean(accuracy['train_score'])\n",
    "test_accuracy = np.mean(accuracy['test_score'])\n",
    "print('The training data accuracy is:' ,train_accuracy * 100 , '%')\n",
    "print('The test data accuracy is:' ,test_accuracy * 100 , '%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elsmjgbNRSdH"
   },
   "outputs": [],
   "source": [
    "class AdaBoost:\n",
    "\n",
    "    def __init__(self, train_data_X, train_data_y, tree_num, test_data_X, test_data_y):\n",
    "        self.train_data_X = train_data_X\n",
    "        self.train_data_y = train_data_y\n",
    "        self.tree_num = tree_num\n",
    "        self.test_data_X = test_data_X\n",
    "        self.test_data_y = test_data_y\n",
    "        self.alphas = None\n",
    "        self.models = None\n",
    "        self.accuracy = []\n",
    "        self.predictions = None\n",
    "\n",
    "    def fit(self):\n",
    "        Evaluation = pd.DataFrame(self.train_data_y.copy())\n",
    "        Evaluation.columns = ['target']\n",
    "        ## TODO:Set the initial weights w = 1/N\n",
    "        Evaluation['weights'] = np.ones(self.train_data_X.shape[0]) * (1 / self.train_data_X.shape[0])\n",
    "\n",
    "        alphas = []  # list of alphas\n",
    "        models = []  # list of trained models\n",
    "        for t in range(self.tree_num):\n",
    "            ## TODO: create a weak decisiontree classifier\n",
    "            Tree_model = DecisionTreeClassifier(criterion='entropy', max_depth=1)\n",
    "            ## TODO: fit the model with train data. set the sample_weight parameter to the 'weights' columns in Evaluation dataframe\n",
    "            model = Tree_model.fit(self.train_data_X, self.train_data_y, sample_weight=Evaluation['weights'])\n",
    "\n",
    "            models.append(model)\n",
    "            predictions = model.predict(self.train_data_X)\n",
    "            score = model.score(self.train_data_X, self.train_data_y)\n",
    "\n",
    "            ## Add this columns to the Evaluation DataFrame\n",
    "            Evaluation['predictions'] = predictions\n",
    "            ## TODO: In each row if the prediction and the target are equal,this column must be '1' and '0' O.W.\n",
    "            Evaluation['evaluation'] = np.where(Evaluation['predictions'] == Evaluation['target'], 1, 0)\n",
    "            ## TODO: In each row if the tha data is missclassified, this column must be 1.\n",
    "            Evaluation['misclassified'] = np.where(Evaluation['predictions'] != Evaluation['target'], 1, 0)\n",
    "\n",
    "\n",
    "            ## TODO: Calculate the misclassification rate and accuracy and then use them to calculate error\n",
    "            accuracy = np.count_nonzero(Evaluation['evaluation']) / Evaluation['evaluation'].shape[0]\n",
    "            misclassification = 1 - accuracy\n",
    "            err = np.dot(Evaluation['weights'], Evaluation['misclassified'])\n",
    "            ## TODO: Calculate the alpha values from the adaboost algorithm\n",
    "            alpha = 0.5 * np.log2((1 - err) / err)\n",
    "            alphas.append(alpha)\n",
    "            ## TODO: update the weights\n",
    "            Evaluation['weights'] = Evaluation['weights'] * np.exp(-1 * alpha * (Evaluation['predictions'] * Evaluation['target']))\n",
    "            Evaluation['weights'] = Evaluation['weights'] / np.sum(Evaluation['weights'])\n",
    "\n",
    "\n",
    "        self.alphas = alphas\n",
    "        self.models = models\n",
    "\n",
    "    def predict(self):\n",
    "        predictions = []\n",
    "        #####################################################################################\n",
    "        # TODO:                                                                              #\n",
    "        # 1- predict target for test data and append each prediction to the predictions list#\n",
    "        # 2- Create a list of accuracies which can be used to plot the accuracy against the #\n",
    "        # number of base learners used for the model                                        #\n",
    "        #####################################################################################\n",
    "        for alpha, model in zip(self.alphas, self.models):\n",
    "            prediction = alpha * model.predict(self.test_data_X)\n",
    "            predictions.append(prediction)\n",
    "            multiple_model_preds = np.sign(np.sum(np.array(predictions), axis=0))\n",
    "            self.accuracy.append(accuracy_score(self.test_data_y, multiple_model_preds))\n",
    "        \n",
    "\n",
    "        self.predictions = np.sign(np.sum(np.array(predictions), axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-by9WfOXRVQG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a number of  100 base models we receive an accuracy of  100.0 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2f62a9c89b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a number of  100 base models we receive an accuracy of  98.24561403508771 %\n"
     ]
    }
   ],
   "source": [
    "# Accuracy - number of base learners plot for training data\n",
    "\n",
    "number_of_base_learners = 100\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax0 = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "model = AdaBoost(X_train,y_train,number_of_base_learners,X_train,y_train)\n",
    "model.fit()\n",
    "model.predict()\n",
    "\n",
    "ax0.plot(range(len(model.accuracy)),model.accuracy,'-b')\n",
    "ax0.set_xlabel('# models used for Boosting ')\n",
    "ax0.set_ylabel('accuracy')\n",
    "print('With a number of ',number_of_base_learners,'base models we receive an accuracy of ',model.accuracy[-1]*100,'%')    \n",
    "                 \n",
    " \n",
    "#################################################################### \n",
    "# TODO: Plot Accuracy - number of base learners plot for test data #\n",
    "#################################################################### \n",
    "model = AdaBoost(X_train,y_train,number_of_base_learners,X_test,y_test)\n",
    "model.fit()\n",
    "accuracies = model.predict()\n",
    "ax0.plot(range(len(model.accuracy)),model.accuracy,'-r')\n",
    "plt.show()  \n",
    "print('With a number of ',number_of_base_learners,'base models we receive an accuracy of ',model.accuracy[-1]*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aHIp-4p9Ravu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2olecphWRi4L"
   },
   "source": [
    "# Feature Selction </br>\n",
    "\n",
    "## problem4. Filtering : correlation coefficient (25 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oe0ynxveRmXS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part 1:  ['worst concave points' 'worst perimeter' 'worst radius'\n",
      " 'mean concave points' 'mean perimeter' 'worst area' 'mean radius'\n",
      " 'mean area' 'mean concavity' 'worst concavity' 'mean compactness'\n",
      " 'worst compactness' 'radius error' 'perimeter error' 'area error']\n",
      "part2 (top 3):  ['worst compactness' 'area error' 'worst concavity']\n",
      "part2 all:  ['worst compactness' 'area error' 'worst concavity' 'perimeter error'\n",
      " 'radius error' 'mean compactness' 'mean area' 'mean radius' 'worst area'\n",
      " 'mean perimeter' 'worst radius']\n",
      "part4(accuracy of perceptron): 0.9824561403508771\n",
      "part4(sorted features):  ['worst compactness' 'concave points error' 'worst fractal dimension'\n",
      " 'mean symmetry' 'texture error' 'mean smoothness' 'smoothness error'\n",
      " 'concavity error' 'mean compactness' 'symmetry error' 'mean perimeter'\n",
      " 'mean radius' 'fractal dimension error' 'worst concavity' 'mean area'\n",
      " 'mean texture' 'mean fractal dimension' 'area error' 'perimeter error'\n",
      " 'compactness error' 'mean concavity' 'worst symmetry' 'worst perimeter'\n",
      " 'worst concave points' 'worst area' 'worst smoothness'\n",
      " 'mean concave points' 'worst texture' 'worst radius' 'radius error']\n",
      "6 2\n",
      "part6(accuracy of perceptron): 0.9122807017543859\n",
      "part7(accuracy of perceptron): 0.8157894736842105\n"
     ]
    }
   ],
   "source": [
    "################################################################################# \n",
    "# TODO:                                                                         #\n",
    "# use 80% of normalized data as train and 20% as test data.(just use the data   # \n",
    "# from last part)                                                               #\n",
    "# 1- compute the correlation coefficient between each feature and target.       #\n",
    "# 2- Report the features that their correlation is more than 0.5                #\n",
    "# 3- compute the correlation between the features you reported in 2nd           #\n",
    "# section and report features that their correlation with other features        #\n",
    "# is less than 0.5                                                              #\n",
    "# 4- use perceptron from sklearn package to classify the data. Report accurracy #\n",
    "# for test data and sort the features based on their weights in perceptron.     #\n",
    "# IMPORTANT: Don't forget to add 1s to the end of feature vectors to be         #\n",
    "# multiplied by bias term of weight in perceptron.                              #\n",
    "# 5- compare the features you reported in section 2 and 3 with the features     #\n",
    "# that have the most weights in perceptron and write your analysis below        #\n",
    "# 6 - Classify data with perceptron and use only the features you repoted in    # \n",
    "# section 2 and report accuracy for test data.                                  #\n",
    "# 7 - Do the same with section 3 and compare accuracies.                        #\n",
    "#################################################################################\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, shuffle=True, test_size= test_ratio)\n",
    "features = np.array(features)\n",
    "###1\n",
    "corrs = []\n",
    "for i in range(X_train.shape[1]):\n",
    "    current_col = X_train[:,i]\n",
    "    corr = np.corrcoef(current_col, y_train)\n",
    "    corrs.append([np.abs(corr[0][1]), i])\n",
    "\n",
    "corrs_sorted = np.array(sorted(corrs, reverse=True))\n",
    "###2\n",
    "selected = corrs_sorted[np.where(corrs_sorted[:, 0] > 0.5)]\n",
    "feature_indexes = selected[:,1].astype(int)\n",
    "print(\"part 1: \" , features[feature_indexes])\n",
    "\n",
    "###3\n",
    "X_selected = X_train[:,feature_indexes]\n",
    "corr_mat = np.corrcoef(X_selected.T)\n",
    "num_less = np.array(np.unique(np.argwhere(np.abs(corr_mat) < 0.5)[:,0], return_counts=True))\n",
    "sorted_num_less = num_less[:, num_less[1].argsort()]\n",
    "top_all = feature_indexes[np.flip(sorted_num_less[0], axis = 0)]\n",
    "top3 = top_all[:3]\n",
    "print(\"part2 (top 3): \", features[top3])\n",
    "print(\"part2 all: \", features[top_all])\n",
    "\n",
    "###4\n",
    "X_train_biased = np.insert(X_train, 0, 1, axis=1)\n",
    "X_test_biased = np.insert(X_test, 0, 1, axis = 1)\n",
    "clf = Perceptron(tol=1e-3)\n",
    "clf.fit(X_train_biased, y_train)\n",
    "\n",
    "preds = clf.predict(X_test_biased)\n",
    "print(\"part4(accuracy of perceptron):\", accuracy_score(y_test, preds))\n",
    "sorted_weight_features = features[np.abs(clf.coef_[0,1:]).argsort()]\n",
    "print(\"part4(sorted features): \", sorted_weight_features)\n",
    "##5\n",
    "num_similar_part2 = 0\n",
    "for f in features[feature_indexes]:\n",
    "    if f in sorted_weight_features[0:15]:\n",
    "        num_similar_part2 += 1\n",
    "num_similar_part3 = 0\n",
    "for f in features[top3]:\n",
    "    if f in sorted_weight_features[0:15]:\n",
    "        num_similar_part3 += 1\n",
    "\n",
    "print(num_similar_part2, num_similar_part3)\n",
    "\n",
    "###6\n",
    "X_selected = np.insert(X_selected, 0, 1, axis=1)\n",
    "clf.fit(X_selected, y_train)\n",
    "X_test_new = X_test[:, feature_indexes]\n",
    "X_test_new = np.insert(X_test_new, 0, 1, axis=1)\n",
    "preds = clf.predict(X_test_new)\n",
    "print(\"part6(accuracy of perceptron):\", accuracy_score(y_test, preds))\n",
    "\n",
    "###7\n",
    "X_selected = np.insert(X_train[:, top3], 0, 1, axis=1)\n",
    "clf.fit(X_selected, y_train)\n",
    "X_test_new = X_test[:, top3]\n",
    "X_test_new = np.insert(X_test_new, 0, 1, axis=1)\n",
    "preds = clf.predict(X_test_new)\n",
    "print(\"part7(accuracy of perceptron):\", accuracy_score(y_test, preds))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o0QJrI36-GNR"
   },
   "source": [
    "explanation of part 5 and 6:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iTC2KZ1h-QO6"
   },
   "source": [
    "As you can see in part 5, many of the features extracted in part 2 and 3 are among the features with the highest weights in the perceptron (i.e. they are more important in classification). This shows that features with more correlation with the label distribution, are more important in classification. also in part 6 you can see that the accuracy has not dropped signifficantly which showes that the features extracted are the more important ones in the course of classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k_XG0iKSRqnE"
   },
   "source": [
    "Question: Is it important to extract features before classifying using methods like decision tree and SVM? why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ro6v3JSBRsd5"
   },
   "source": [
    "Feature selection is important because:\n",
    "<ul>\n",
    "       <li> curse of dimentionality\n",
    "       <li> overfitting: the more features we have there is a higher risk of overfitting\n",
    "       <li> computational cost: most classification algorithms have exponential running time with respect to the dimention of the data.\n",
    "       <li> the quality of data: There are many features in the original data that do not help classify the data\n",
    "</ul>\n",
    "So, yes. It is important to do feature selection before doing classification. of course due to the fact that decsision trees are more prone to overfitting, than for example, SVM, it is more important in this case to do feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eQjRm5a6j8KZ"
   },
   "source": [
    "## problem 5. mRMR (10 bonus points) </br>\n",
    "In this part you should write your own code and classify the data using mRMR method.You can use \"pymrmr\" package for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQs-LPupRoDx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9298245614035088\n"
     ]
    }
   ],
   "source": [
    "import pymrmr\n",
    "\n",
    "cancer = load_breast_cancer()  ## change if the data set changed\n",
    "df = pd.DataFrame(np.c_[cancer[\"target\"], cancer[\"data\"]], columns = np.append([\"target\"], cancer[\"feature_names\"]))\n",
    "features = ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n",
    "cancer.target = np.where(cancer.target==0, -1, cancer.target)\n",
    "\n",
    "#X = cancer[\"data\"]\n",
    "#Y = cancer[\"target\"]\n",
    "\n",
    "X_train ,X_test ,X_val ,y_train ,y_test ,y_val = None ,None ,None ,None ,None ,None\n",
    "\n",
    "\n",
    "\n",
    "best_features = pymrmr.mRMR(df, 'MIQ', 15)\n",
    "X = np.array(df[best_features])\n",
    "Y = np.array(df[\"target\"])\n",
    "\n",
    "test_ratio = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, shuffle=True, test_size= test_ratio)\n",
    "\n",
    "X_train_biased = np.insert(X_train, 0, 1, axis=1)\n",
    "X_test_biased = np.insert(X_test, 0, 1, axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "clf = Perceptron(random_state=105)\n",
    "clf.fit(X_train_biased, y_train)\n",
    "preds = clf.predict(X_test_biased)\n",
    "print(accuracy_score(y_test, preds))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MLBio_HW3_P.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
